{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Adapted from [Dive into Deep Learning](https://d2l.ai/index.html), Chapter 7, Section 6. The authors are prominent Amazon data scientists, so they work primarily with the [MXNet](https://mxnet.apache.org/versions/1.7.0/) framework rather than [TensorFlow](https://www.tensorflow.org/) or [PyTorch](https://pytorch.org/). As such, this assignment will rely on MXNet as well. ",
      "metadata": {
        "id": "qi9L0veTKe7M",
        "cell_id": "00000-a2c89422-bf30-41f4-8df8-141a0025401b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "The following additional libraries are needed to run this\nnotebook. Note that running on Colab is experimental, please report a Github\nissue if you have any problem.",
      "metadata": {
        "id": "3It3ictg77Bq",
        "cell_id": "00001-110d6f90-5e3f-46ca-a892-09fe8ea759fc",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## If running this notebook in Colab, make sure to navigate to Runtime > Change runtime type, select GPU in the Hardward accelerator drop-down menu, and click Save *before* running the following code cell! Otherwise, `mxnet-cu101` won't install.",
      "metadata": {
        "id": "tYaw1beRgYDV",
        "cell_id": "00002-2bf28738-05d6-45a2-83f4-72455b5da85c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q2SU8JE77Br",
        "cell_id": "00003-a99a11b0-3fec-4bff-b3ae-fc686e660fe4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "689d87f",
        "execution_millis": 8783,
        "execution_start": 1618630974543,
        "deepnote_cell_type": "code"
      },
      "source": "!pip install d2l==0.15.1\n!pip install -U mxnet-cu101==1.7.0",
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: d2l==0.15.1 in /root/venv/lib/python3.6/site-packages (0.15.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.19.5)\nRequirement already satisfied: pandas in /shared-libs/python3.6/py/lib/python3.6/site-packages (from d2l==0.15.1) (1.1.5)\nRequirement already satisfied: jupyter in /root/venv/lib/python3.6/site-packages (from d2l==0.15.1) (1.0.0)\nRequirement already satisfied: matplotlib in /shared-libs/python3.6/py/lib/python3.6/site-packages (from d2l==0.15.1) (3.3.4)\nRequirement already satisfied: nbconvert in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jupyter->d2l==0.15.1) (6.0.7)\nRequirement already satisfied: notebook in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jupyter->d2l==0.15.1) (7.0.0.dev0)\nRequirement already satisfied: ipykernel in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jupyter->d2l==0.15.1) (5.5.3)\nRequirement already satisfied: ipywidgets in /root/venv/lib/python3.6/site-packages (from jupyter->d2l==0.15.1) (7.6.3)\nRequirement already satisfied: jupyter-console in /root/venv/lib/python3.6/site-packages (from jupyter->d2l==0.15.1) (6.4.0)\nRequirement already satisfied: qtconsole in /root/venv/lib/python3.6/site-packages (from jupyter->d2l==0.15.1) (5.0.3)\nRequirement already satisfied: traitlets>=4.1.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipykernel->jupyter->d2l==0.15.1) (4.3.3)\nRequirement already satisfied: jupyter-client in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipykernel->jupyter->d2l==0.15.1) (6.1.12)\nRequirement already satisfied: tornado>=4.2 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipykernel->jupyter->d2l==0.15.1) (6.1)\nRequirement already satisfied: ipython>=5.0.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipykernel->jupyter->d2l==0.15.1) (7.16.1)\nRequirement already satisfied: pickleshare in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (0.7.5)\nRequirement already satisfied: pygments in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (2.8.1)\nRequirement already satisfied: decorator in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (5.0.6)\nRequirement already satisfied: jedi>=0.10 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (0.17.2)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (3.0.18)\nRequirement already satisfied: backcall in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (0.2.0)\nRequirement already satisfied: setuptools>=18.5 in /root/venv/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (54.1.2)\nRequirement already satisfied: pexpect in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (4.8.0)\nRequirement already satisfied: parso<0.8.0,>=0.7.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (0.7.1)\nRequirement already satisfied: wcwidth in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==0.15.1) (0.2.5)\nRequirement already satisfied: ipython-genutils in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel->jupyter->d2l==0.15.1) (0.2.0)\nRequirement already satisfied: six in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel->jupyter->d2l==0.15.1) (1.15.0)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /root/venv/lib/python3.6/site-packages (from ipywidgets->jupyter->d2l==0.15.1) (3.5.1)\nRequirement already satisfied: nbformat>=4.2.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from ipywidgets->jupyter->d2l==0.15.1) (5.1.3)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /root/venv/lib/python3.6/site-packages (from ipywidgets->jupyter->d2l==0.15.1) (1.0.0)\nRequirement already satisfied: jupyter-core in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (4.7.1)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (3.2.0)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (3.10.1)\nRequirement already satisfied: pyrsistent>=0.14.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (0.17.3)\nRequirement already satisfied: attrs>=17.4.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (20.3.0)\nRequirement already satisfied: pyzmq>=17 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from notebook->jupyter->d2l==0.15.1) (22.0.3)\nRequirement already satisfied: prometheus-client in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from notebook->jupyter->d2l==0.15.1) (0.10.1)\nRequirement already satisfied: terminado>=0.8.3 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from notebook->jupyter->d2l==0.15.1) (0.9.4)\nRequirement already satisfied: Send2Trash>=1.5.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from notebook->jupyter->d2l==0.15.1) (1.5.0)\nRequirement already satisfied: argon2-cffi in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from notebook->jupyter->d2l==0.15.1) (20.1.0)\nRequirement already satisfied: jinja2 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from notebook->jupyter->d2l==0.15.1) (2.11.3)\nRequirement already satisfied: python-dateutil>=2.1 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jupyter-client->ipykernel->jupyter->d2l==0.15.1) (2.8.1)\nRequirement already satisfied: ptyprocess in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from terminado>=0.8.3->notebook->jupyter->d2l==0.15.1) (0.7.0)\nRequirement already satisfied: cffi>=1.0.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from argon2-cffi->notebook->jupyter->d2l==0.15.1) (1.14.5)\nRequirement already satisfied: pycparser in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->d2l==0.15.1) (2.20)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (3.4.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.15.1) (3.7.4.3)\nRequirement already satisfied: MarkupSafe>=0.23 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from jinja2->notebook->jupyter->d2l==0.15.1) (1.1.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from matplotlib->d2l==0.15.1) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.6/py/lib/python3.6/site-packages (from matplotlib->d2l==0.15.1) (1.3.1)\nRequirement already satisfied: pillow>=6.2.0 in /shared-libs/python3.6/py/lib/python3.6/site-packages (from matplotlib->d2l==0.15.1) (8.2.0)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.6/py/lib/python3.6/site-packages (from matplotlib->d2l==0.15.1) (0.10.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (0.3)\nRequirement already satisfied: pandocfilters>=1.4.1 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (1.4.3)\nRequirement already satisfied: defusedxml in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (0.7.1)\nRequirement already satisfied: jupyterlab-pygments in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (0.1.2)\nRequirement already satisfied: bleach in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (3.3.0)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (0.5.3)\nRequirement already satisfied: testpath in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (0.4.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbconvert->jupyter->d2l==0.15.1) (0.8.4)\nRequirement already satisfied: async-generator in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->d2l==0.15.1) (1.10)\nRequirement already satisfied: nest-asyncio in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->d2l==0.15.1) (1.5.1)\nRequirement already satisfied: webencodings in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from bleach->nbconvert->jupyter->d2l==0.15.1) (0.5.1)\nRequirement already satisfied: packaging in /shared-libs/python3.6/py-core/lib/python3.6/site-packages (from bleach->nbconvert->jupyter->d2l==0.15.1) (20.9)\nRequirement already satisfied: pytz>=2017.2 in /shared-libs/python3.6/py/lib/python3.6/site-packages (from pandas->d2l==0.15.1) (2021.1)\nRequirement already satisfied: qtpy in /root/venv/lib/python3.6/site-packages (from qtconsole->jupyter->d2l==0.15.1) (1.9.0)\nRequirement already satisfied: mxnet-cu101==1.7.0 in /root/venv/lib/python3.6/site-packages (1.7.0)\nRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (2.25.1)\nRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (1.19.5)\nRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /root/venv/lib/python3.6/site-packages (from mxnet-cu101==1.7.0) (0.8.4)\nRequirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.6)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.26.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (4.0.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Residual Networks (ResNets)\n:label:`sec_resnet`\n\nAs we design increasingly deeper networks it becomes imperative to understand how adding layers can increase the complexity and expressiveness of the network.\nEven more important is the ability to design networks where adding layers makes networks strictly more expressive rather than just different.\nTo make some progress we need a bit of mathematics.\n\n\n## Function Classes\n\nConsider $\\mathcal{F}$, the class of functions that a specific network architecture (together with learning rates and other hyperparameter settings) can reach.\nThat is, for all $f \\in \\mathcal{F}$ there exists some set of parameters (e.g., weights and biases) that can be obtained through training on a suitable dataset.\nLet us assume that $f^*$ is the \"truth\" function that we really would like to find.\nIf it is in $\\mathcal{F}$, we are in good shape but typically we will not be quite so lucky.\nInstead, we will try to find some $f^*_\\mathcal{F}$ which is our best bet within $\\mathcal{F}$.\nFor instance, \ngiven a dataset with features $\\mathbf{X}$\nand labels $\\mathbf{y}$,\nwe might try finding it by solving the following optimization problem:\n\n$$f^*_\\mathcal{F} \\stackrel{\\mathrm{def}}{=} \\mathop{\\mathrm{argmin}}_f L(\\mathbf{X}, \\mathbf{y}, f) \\text{ subject to } f \\in \\mathcal{F}.$$\n\nIt is only reasonable to assume that if we design a different and more powerful architecture $\\mathcal{F}'$ we should arrive at a better outcome. In other words, we would expect that $f^*_{\\mathcal{F}'}$ is \"better\" than $f^*_{\\mathcal{F}}$. However, if $\\mathcal{F} \\not\\subseteq \\mathcal{F}'$ there is no guarantee that this should even happen. In fact, $f^*_{\\mathcal{F}'}$ might well be worse. \nAs illustrated by :numref:`fig_functionclasses`,\nfor non-nested function classes, a larger function class does not always move closer to the \"truth\" function $f^*$. For instance,\non the left of :numref:`fig_functionclasses`,\nthough $\\mathcal{F}_3$ is closer to $f^*$ than $\\mathcal{F}_1$, $\\mathcal{F}_6$ moves away and there is no guarantee that further increasing the complexity can reduce the distance from $f^*$.\nWith nested function classes\nwhere $\\mathcal{F}_1 \\subseteq \\ldots \\subseteq \\mathcal{F}_6$\non the right of :numref:`fig_functionclasses`,\nwe can avoid the aforementioned issue from the non-nested function classes.\n\n\n![For non-nested function classes, a larger (indicated by area) function class does not guarantee to get closer to the \"truth\" function ($f^*$). This does not happen in nested function classes.](http://d2l.ai/_images/functionclasses.svg)\n:label:`fig_functionclasses`\n\nThus,\nonly if larger function classes contain the smaller ones are we guaranteed that increasing them strictly increases the expressive power of the network.\nFor deep neural networks,\nif we can \ntrain the newly-added layer into an identity function $f(\\mathbf{x}) = \\mathbf{x}$, the new model will be as effective as the original model. As the new model may get a better solution to fit the training dataset, the added layer might make it easier to reduce training errors.\n\nThis is the question that He et al. considered when working on very deep computer vision models :cite:`He.Zhang.Ren.ea.2016`. \nAt the heart of their proposed *residual network* (*ResNet*) is the idea that every additional layer should \nmore easily\ncontain the identity function as one of its elements. \nThese considerations are rather profound but they led to a surprisingly simple\nsolution, a *residual block*.\nWith it, ResNet won the ImageNet Large Scale Visual Recognition Challenge in 2015. The design had a profound influence on how to\nbuild deep neural networks.\n\n\n\n## Residual Blocks\n\nLet us focus on a local part of a neural network, as depicted in :numref:`fig_residual_block`. Denote the input by $\\mathbf{x}$.\nWe assume that the desired underlying mapping we want to obtain by learning is $f(\\mathbf{x})$, to be used as the input to the activation function on the top.\nOn the left of :numref:`fig_residual_block`,\nthe portion within the dotted-line box \nmust directly learn the mapping $f(\\mathbf{x})$.\nOn the right,\nthe portion within the dotted-line box\nneeds to\nlearn the *residual mapping* $f(\\mathbf{x}) - \\mathbf{x}$,\nwhich is how the residual block derives its name.\nIf the identity mapping $f(\\mathbf{x}) = \\mathbf{x}$ is the desired underlying mapping,\nthe residual mapping is easier to learn:\nwe only need to push the weights and biases\nof the\nupper weight layer (e.g., fully-connected layer and convolutional layer)\nwithin the dotted-line box\nto zero.\nThe right figure in :numref:`fig_residual_block` illustrates the  *residual block* of ResNet,\nwhere the solid line carrying the layer input \n$\\mathbf{x}$ to the addition operator\nis called a *residual connection* (or *shortcut connection*).\nWith residual blocks, inputs can \nforward propagate faster through the residual connections across layers.\n\n![A regular block (left) and a residual block (right).](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/residual-block.svg?raw=1)\n:label:`fig_residual_block`\n\n\nResNet follows VGG's full $3\\times 3$ convolutional layer design. The residual block has two $3\\times 3$ convolutional layers with the same number of output channels. Each convolutional layer is followed by a batch normalization layer and a ReLU activation function. Then, we skip these two convolution operations and add the input directly before the final ReLU activation function.\nThis kind of design requires that the output of the two convolutional layers has to be of the same shape as the input, so that they can be added together. If we want to change the number of channels, we need to introduce an additional $1\\times 1$ convolutional layer to transform the input into the desired shape for the addition operation. ",
      "metadata": {
        "origin_pos": 0,
        "id": "i6RvPIsd77Bx",
        "cell_id": "00004-0a037731-17a4-462d-87bb-79c9dcac8eff",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "The code below generates two types of networks: one where we add the input to the output before applying the ReLU nonlinearity whenever `use_1x1conv=False`, and one where we adjust channels and resolution by means of a $1 \\times 1$ convolution before adding. :numref:`fig_resnet_block` illustrates this:\n\n![ResNet block with and without $1 \\times 1$ convolution.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/resnet-block.svg?raw=1)\n:label:`fig_resnet_block`\n",
      "metadata": {
        "origin_pos": 4,
        "id": "7jtg4SUo77B1",
        "cell_id": "00005-8f6740bc-e623-4a1f-892d-8c4ed75b7f13",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise: Implement the figures above as the `Residual` class. \nNotes: \n1. The d2l module allows us to use utility functions developed for the Dive into Deep Learning book.\n2. MXNet's np and npx modules allow for Numpy-compatible coding, which MXNet's basic ndarray module doesn't, as [this](https://github.com/apache/incubator-mxnet/issues/14253) post illustrates. You might also find [this](https://stackoverflow.com/questions/58933738/mxnet-import-nd-or-np-to-use-arrays) Stack Overflow query helpful.\n3. [Gluon](https://mxnet.apache.org/versions/1.6/api/python/docs/api/gluon/index.html) is to MXNet as Keras is to TensorFlow.\n4. You might find the following functions useful: [`mxnet.gluon.nn.Conv2D()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.Conv2D), [`mxnet.gluon.nn.BatchNorm()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.BatchNorm), [`mxnet.gluon.nn.Activation()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.Activation), [`npx.relu()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/ndarray/op/index.html#mxnet.ndarray.op.relu).\n",
      "metadata": {
        "id": "vMkpAKlSnYF9",
        "cell_id": "00006-a1a70dc0-d381-4f3a-abe8-a6967b185e32",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "mxnet"
        ],
        "id": "-MCesdab77By",
        "cell_id": "00007-6f53b0e3-a988-4a3c-829d-2cac88b03a09",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d54c57ca",
        "execution_millis": 31,
        "execution_start": 1618630983336,
        "deepnote_cell_type": "code"
      },
      "source": "from d2l import mxnet as d2l\nfrom mxnet import np, npx\nfrom mxnet.gluon import nn\nnpx.set_np()\n\nclass Residual(nn.Block):  #@save\n    \"\"\"The Residual block of ResNet.\"\"\"\n    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n        ### START CODE HERE ###\n        super().__init__(**kwargs)\n        # Convolutional layer with num_channels output channels, kernel size of 3, \n        # and padding of 1. Pass in the strides used to instantiate the class.\n        self.conv1 = nn.Conv2D(num_channels, 3, strides=strides, padding=1)\n        # Convolutional layer like the first, but with the default stride of 1\n        self.conv2 = nn.Conv2D(num_channels, 3, strides=1, padding=1)\n        # If we're using a 1 x 1 convolution on the residual branch...\n        if use_1x1conv:\n            # Convolutional layer with num_channels output channels and kernel size of 1. \n            # Pass in the strides used to instantiate the class.\n            self.conv3 = nn.Conv2D(num_channels, 1, strides=strides)\n        else:\n            # DON'T replace the None on the next line!\n            self.conv3 = None\n        # Batch normalization. Use the default parameters. \n        self.bn1 = nn.BatchNorm()\n        # Batch normalization. Use the default parameters.\n        self.bn2 = nn.BatchNorm()\n        ### END CODE HERE ###\n\n    def forward(self, X):\n        ### START CODE HERE ###\n        # Pass the input layer through the first convolutional layer\n        Y = self.conv1(X)\n        # First batch normalization layer\n        Y = self.bn1(Y)\n        # ReLU activation\n        Y = npx.relu(Y)\n        # Second convolutional layer\n        Y = self.conv2(Y)\n        # Second batch normalization layer \n        Y = self.bn2(Y)\n        # If the third convolutional layer exists, pass the input layer through it\n        if self.conv3:\n            X = self.conv3(Y)\n        # Add the two branches together, then apply a ReLU activation to the summed layer\n        return npx.relu(Y + X)\n        ### END CODE HERE ###",
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "libcudart.so.10.1: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-379fdae4d664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgluon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/venv/lib/python3.6/site-packages/d2l/mxnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Defined in file: ./chapter_preface/index.md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgluon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/venv/lib/python3.6/site-packages/mxnet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\"\"\"MXNet: a concise, fast and flexible framework for deep learning.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_pinned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/venv/lib/python3.6/site-packages/mxnet/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassproperty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_metaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MXClassPropertyMetaClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LIB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/venv/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;31m# library instance of mxnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;31m# type definitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/venv/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;34m\"\"\"Load library by searching possible path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlib_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_lib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;31m# DMatrix functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: libcudart.so.10.1: cannot open shared object file: No such file or directory"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now let us look at a situation where the input and output are of the same shape.",
      "metadata": {
        "id": "-Mh0gv-x2oRo",
        "cell_id": "00008-a8546ddc-0c9e-4ac4-94f3-708b11bc79ea",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "mxnet"
        ],
        "id": "IScmkMsV77B1",
        "cell_id": "00009-bb631849-7994-43cb-b00e-3bcbb0b73073",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b25945e6",
        "execution_start": 1618630985675,
        "execution_millis": 15,
        "deepnote_cell_type": "code"
      },
      "source": "blk = Residual(3)\nblk.initialize()\nX = np.random.uniform(size=(4, 3, 6, 6))\nblk(X).shape",
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Residual' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-05f51ebfce64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Residual' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We also have the option to halve the output height and width while increasing the number of output channels.\n",
      "metadata": {
        "origin_pos": 8,
        "id": "ZSlypLnk77B4",
        "cell_id": "00010-67c302ea-c6a2-4063-accc-45cfdd1370fd",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "mxnet"
        ],
        "id": "IJow9uXS77B5",
        "cell_id": "00011-b0424277-c607-4346-8f07-86199c5d2281",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "515b9ff",
        "execution_start": 1618630986757,
        "execution_millis": 12,
        "deepnote_cell_type": "code"
      },
      "source": "blk = Residual(6, use_1x1conv=True, strides=2)\nblk.initialize()\nblk(X).shape",
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Residual' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-92784c728532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_1x1conv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Residual' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## ResNet Model\n\n### Exercise: Instantiate the ResNet model with Gluon's [`nn.Sequential()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.Sequential) API, then add to the model as follows: \n\nThe first two layers of ResNet are the same as those of GoogLeNet: the $7\\times 7$ convolutional layer with 64 output channels and a stride of 2 is followed by the $3\\times 3$ maximum pooling layer with a stride of 2. The difference is the batch normalization layer added after each convolutional layer in ResNet.\n\nYou may find Gluon's [`nn.Activation()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.Activation) and [`nn.MaxPool2D()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.MaxPool2D) useful.\n",
      "metadata": {
        "origin_pos": 12,
        "id": "v9UMmyCE77B7",
        "cell_id": "00012-165bb673-446b-4b43-9ef7-64d796027068",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "mxnet"
        ],
        "id": "XSyCeayC77B8",
        "cell_id": "00013-cdd41150-aa22-4af8-a89b-f0e25723692d",
        "deepnote_cell_type": "code"
      },
      "source": "### START CODE HERE ###\n# Instantiate the model\nnet = nn.Sequential()\n# Start adding to the model\nnet.add(# Convolutional layer\n        nn.Conv2D(64, kernel_size=1, strides=2),\n        # Batch normalization\n        nn.BatchNorm(), \n        # ReLU activation\n        nn.relu(),\n        # Max pooling\n        nn.MaxPool2D(pool_size=(3, 3), strides=2))\n### END CODE HERE ###",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "GoogLeNet uses four modules made up of Inception blocks.\nHowever, ResNet uses four modules made up of residual blocks, each of which uses several residual blocks with the same number of output channels. \nThe number of channels in the first module is the same as the number of input channels. Since a maximum pooling layer with a stride of 2 has already been used, it is not necessary to reduce the height and width. In the first residual block for each of the subsequent modules, the number of channels is doubled compared with that of the previous module, and the height and width are halved.\n\nNow, we implement this module. Note that special processing has been performed on the first module.\n",
      "metadata": {
        "origin_pos": 16,
        "id": "InGdMxtV77B_",
        "cell_id": "00014-995866a7-ceb6-4490-b15e-afce3fd970c1",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise: Build a function which wraps around a `Residual` block as defined earlier. Make use of the `nn.Sequential()` API and the `add()` method for MXNet models. Give the first block all possible default arguments.",
      "metadata": {
        "id": "LX07kZHKNE1t",
        "cell_id": "00015-c2cb5bd3-edbd-4cb8-9bcc-6c8c70bc564b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 17,
        "tab": [
          "mxnet"
        ],
        "id": "r79QAAS277B_",
        "cell_id": "00016-3db56404-9e41-4483-a80d-8addcdbacf18",
        "deepnote_cell_type": "code"
      },
      "source": "def resnet_block(num_channels, num_residuals, first_block=False):\n    ### START CODE HERE ###\n    # Initialize the ResNet block\n    blk = nn.Sequential()\n    # Iterate through the residual sub-blocks\n    for i in range(num_residuals):\n        # If this is the first sub-block but NOT the first ResNet block of the whole model...\n        if first_block:\n            # Add a residual sub-block with num_channels output channels, \n            # 1 x 1 convolutions, and a stride of 2\n            blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n        else:\n            # If not, add a residual sub-block with num_channels output channels \n            # and otherwise default arguments\n            blk.add(Residual(num_channels))\n    # Return the ResNet block\n    return blk\n    ### END CODE HERE ###",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Then, we add all the modules to ResNet. Here, two residual blocks are used for each module.\n",
      "metadata": {
        "origin_pos": 20,
        "id": "HdwX7M9d77CE",
        "cell_id": "00017-ff7a1eb9-6e61-4f6a-9508-d7547ad82276",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise: Add 4 ResNet blocks to the model, with 64, 128, 256, and 512 respective output channels, and each with 2 sub-blocks. Don't forget about the `first_block` parameter!",
      "metadata": {
        "id": "o_onPSdRvWNR",
        "cell_id": "00018-483c3767-9131-4977-9dcf-4934504e10f3",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 21,
        "tab": [
          "mxnet"
        ],
        "id": "cLY4Gyv377CF",
        "cell_id": "00019-2292fc2a-26f0-453d-98ec-62eacc674855",
        "deepnote_cell_type": "code"
      },
      "source": "### START CODE HERE ###\nNone\n### END CODE HERE ###",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise: Finally, just like GoogLeNet, we add a global average pooling layer, followed by the fully-connected layer output.\n",
      "metadata": {
        "origin_pos": 24,
        "id": "HvYuXVWd77CK",
        "cell_id": "00020-5ddaabe4-0ef1-4c30-9c0c-af3a13edb348",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 25,
        "tab": [
          "mxnet"
        ],
        "id": "dx2kUaB877CK",
        "cell_id": "00021-ecb15dce-9750-4334-922c-0771e55badd2",
        "deepnote_cell_type": "code"
      },
      "source": "### START CODE HERE ###\nNone\n### END CODE HERE ###",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "There are 4 convolutional layers in each module (excluding the $1\\times 1$ convolutional layer). Together with the first $7\\times 7$ convolutional layer and the final fully-connected layer, there are 18 layers in total. Therefore, this model is commonly known as ResNet-18.\nBy configuring different numbers of channels and residual blocks in the module, we can create different ResNet models, such as the deeper 152-layer ResNet-152. Although the main architecture of ResNet is similar to that of GoogLeNet, ResNet's structure is simpler and easier to modify. All these factors have resulted in the rapid and widespread use of ResNet. :numref:`fig_resnet18` depicts the full ResNet-18.\n\n![The ResNet-18 architecture.](http://d2l.ai/_images/resnet18.svg)\n:label:`fig_resnet18`\n",
      "metadata": {
        "origin_pos": 28,
        "id": "4ibpfSd977CN",
        "cell_id": "00022-29f85771-d53f-4add-8798-d6103333b7a2",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise: Before training ResNet, let us observe how the input shape changes across different modules in ResNet. As in all the previous architectures, the resolution decreases while the number of channels increases up until the point where a global average pooling layer aggregates all features. Print the output shape of each module in the model.",
      "metadata": {
        "id": "v4sBmWZc1INk",
        "cell_id": "00023-fe835cfb-2233-470d-88d6-90be7bbec213",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 29,
        "tab": [
          "mxnet"
        ],
        "id": "CbXajIRG77CN",
        "cell_id": "00024-3f841cd6-7ff9-4354-a3d9-28ea97ad5329",
        "deepnote_cell_type": "code"
      },
      "source": "# Initialize the input with a random array\nX = np.random.uniform(size=(1, 1, 224, 224))\n# Initialize the model\nnet.initialize()\n### START CODE HERE ###\n# Loop over the layers in the model\nfor layer in None:\n    # Apply the current layer to its input or the output of the previous layer\n    X = \n    # Print the current layer's name and the output's shape\n    print(None, 'output shape:\\t', None)\n### END CODE HERE ###",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Expected Output: \n```\nconv5 output shape:\t (1, 64, 112, 112)\nbatchnorm4 output shape:\t (1, 64, 112, 112)\nrelu0 output shape:\t (1, 64, 112, 112)\npool0 output shape:\t (1, 64, 56, 56)\nsequential1 output shape:\t (1, 64, 56, 56)\nsequential2 output shape:\t (1, 128, 28, 28)\nsequential3 output shape:\t (1, 256, 14, 14)\nsequential4 output shape:\t (1, 512, 7, 7)\npool1 output shape:\t (1, 512, 1, 1)\ndense0 output shape:\t (1, 10)\n```",
      "metadata": {
        "id": "6EY59nfUzrJe",
        "cell_id": "00025-b626422d-fc8f-4dcf-b8a8-eeac281ac1b1",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise: For a more detailed look, use the model's [`summary()`](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/block.html#mxnet.gluon.Block.summary) method",
      "metadata": {
        "id": "5Mg6T7Tx2XQz",
        "cell_id": "00026-389669c3-184f-4a38-8ee5-fee32ba5714c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mab_Fgd3z0eg",
        "cell_id": "00027-e6ff0ca7-dbd5-49fa-992b-8ccd52f959ee",
        "deepnote_cell_type": "code"
      },
      "source": "### START CODE HERE ###\n# Initialize the input, consisting of 1 example, 1 output channel, and a pixel height and width of 224\nX = None\n# Reinitialize the model\n# HINT: Use the force_reinit parameter\nNone\n# Summarize the model\nNone\n### END CODE HERE ###",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Expected Output: \n```\n--------------------------------------------------------------------------------\n        Layer (type)                                Output Shape         Param #\n================================================================================\n               Input                            (1, 1, 224, 224)               0\n            Conv2D-1                           (1, 64, 112, 112)            3200\n         BatchNorm-2                           (1, 64, 112, 112)             256\n        Activation-3                           (1, 64, 112, 112)               0\n         MaxPool2D-4                             (1, 64, 56, 56)               0\n            Conv2D-5                             (1, 64, 56, 56)           36928\n         BatchNorm-6                             (1, 64, 56, 56)             256\n            Conv2D-7                             (1, 64, 56, 56)           36928\n         BatchNorm-8                             (1, 64, 56, 56)             256\n          Residual-9                             (1, 64, 56, 56)               0\n           Conv2D-10                             (1, 64, 56, 56)           36928\n        BatchNorm-11                             (1, 64, 56, 56)             256\n           Conv2D-12                             (1, 64, 56, 56)           36928\n        BatchNorm-13                             (1, 64, 56, 56)             256\n         Residual-14                             (1, 64, 56, 56)               0\n           Conv2D-15                            (1, 128, 28, 28)           73856\n        BatchNorm-16                            (1, 128, 28, 28)             512\n           Conv2D-17                            (1, 128, 28, 28)          147584\n        BatchNorm-18                            (1, 128, 28, 28)             512\n           Conv2D-19                            (1, 128, 28, 28)            8320\n         Residual-20                            (1, 128, 28, 28)               0\n           Conv2D-21                            (1, 128, 28, 28)          147584\n        BatchNorm-22                            (1, 128, 28, 28)             512\n           Conv2D-23                            (1, 128, 28, 28)          147584\n        BatchNorm-24                            (1, 128, 28, 28)             512\n         Residual-25                            (1, 128, 28, 28)               0\n           Conv2D-26                            (1, 256, 14, 14)          295168\n        BatchNorm-27                            (1, 256, 14, 14)            1024\n           Conv2D-28                            (1, 256, 14, 14)          590080\n        BatchNorm-29                            (1, 256, 14, 14)            1024\n           Conv2D-30                            (1, 256, 14, 14)           33024\n         Residual-31                            (1, 256, 14, 14)               0\n           Conv2D-32                            (1, 256, 14, 14)          590080\n        BatchNorm-33                            (1, 256, 14, 14)            1024\n           Conv2D-34                            (1, 256, 14, 14)          590080\n        BatchNorm-35                            (1, 256, 14, 14)            1024\n         Residual-36                            (1, 256, 14, 14)               0\n           Conv2D-37                              (1, 512, 7, 7)         1180160\n        BatchNorm-38                              (1, 512, 7, 7)            2048\n           Conv2D-39                              (1, 512, 7, 7)         2359808\n        BatchNorm-40                              (1, 512, 7, 7)            2048\n           Conv2D-41                              (1, 512, 7, 7)          131584\n         Residual-42                              (1, 512, 7, 7)               0\n           Conv2D-43                              (1, 512, 7, 7)         2359808\n        BatchNorm-44                              (1, 512, 7, 7)            2048\n           Conv2D-45                              (1, 512, 7, 7)         2359808\n        BatchNorm-46                              (1, 512, 7, 7)            2048\n         Residual-47                              (1, 512, 7, 7)               0\n  GlobalAvgPool2D-48                              (1, 512, 1, 1)               0\n            Dense-49                                     (1, 10)            5130\n================================================================================\nParameters in forward computation graph, duplicate included\n   Total params: 11186186\n   Trainable params: 11178378\n   Non-trainable params: 7808\nShared params in forward computation graph: 0\nUnique parameters in model: 11186186\n--------------------------------------------------------------------------------\n```",
      "metadata": {
        "id": "E18i4zci5DKD",
        "cell_id": "00028-d910b651-8200-48aa-881b-29b14a9ca4ab",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Training\n\n### Train the ResNet on the Fashion-MNIST dataset. Notes: \n1. This process takes approximately 8 minutes when running a Colab on a single GPU \n2. The next cell uses utility functions developed for the Dive into Deep Learning (d2l) book\n",
      "metadata": {
        "origin_pos": 32,
        "id": "t4VsaGCD77CQ",
        "cell_id": "00029-7d0e9a4d-eceb-491c-aff4-4cfc45616b36",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 33,
        "tab": [
          "mxnet"
        ],
        "id": "VBaUlpeS77CR",
        "cell_id": "00030-9e4135fb-cc79-4280-a8ba-e89be045ad2f",
        "deepnote_cell_type": "code"
      },
      "source": "lr, num_epochs, batch_size = 0.05, 10, 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\nd2l.train_ch6(net, train_iter, test_iter, num_epochs, lr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Summary\n\n* Nested function classes are desirable. Learning an additional layer in deep neural networks as an identity function (though this is an extreme case) should be made easy.\n* The residual mapping can learn the identity function more easily, such as pushing parameters in the weight layer to zero.\n* We can train an effective deep neural network by having residual blocks. Inputs can forward propagate faster through the residual connections across layers.\n* ResNet had a major influence on the design of subsequent deep neural networks, both for convolutional and sequential nature.\n",
      "metadata": {
        "origin_pos": 34,
        "id": "NGesxlGC77CT",
        "cell_id": "00031-5eaf6512-53b8-45c9-836f-60d24405eb9b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6e7b673f-abd3-4fa0-904e-601247e2bdef' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "5.4_ResNet.ipynb",
      "provenance": [
        {
          "file_id": "1vFtPWM6QGkRz28tEIv9WA3GwsgLFabki",
          "timestamp": 1605144154220
        },
        {
          "file_id": "https://github.com/d2l-ai/d2l-en-colab/blob/master/chapter_convolutional-modern/resnet.ipynb",
          "timestamp": 1605075199105
        }
      ],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "deepnote_notebook_id": "e76cafb3-aa34-458a-9574-dd4e680240db",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}